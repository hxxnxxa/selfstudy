<div align='center'>
<h1>Character decomposition to resolve class imbalance problem in Hangul OCR</h1>
</div>

<h2>Author</h2>
<li>현대자동차</li> 
<li>김건욱, 손재민, 이강휴, 민재식</li>
<li>Accepted 12 Aug 2022</li>


<h2>Abstract</h2>
<li>한글 OCR에서 클래스 불균형 문제를 해결하기 위한 문자 분해</li>
<li>한글 OCR(Optical Character Recognition)에 대한 새로운 접근 방식 제시</li>
<li>한글은 11,172개의 서로 다른 문자를 52개 자소로 표현할 수 있는 글자로 각 문자를 자소의 조합으로 표현할 수 있다.</li>
<li>전체 문자 수가 신경망의 용량을 압도할 수 있기 때문에 기존 OCR 인코딩 방식은 자주 사용하는 더 작은 문자 집합을 미리 정의한다.</li>
<li><b>자소 인코딩(grapheme encoding)</b>이 한글 OCR에 효율적일 뿐만 아니라 성능도 있음을 보여준다.</li>
<li>여기서 제시하는 네트워크는 한글 OCR의 두 가지 주요 문제인 클래스 불균형과 대상 클래스 선택을 해결한다는 것을 보여준다.</li>

<h2>1. Introduction</h2>

<b>1) 문제점 제시</b> 
<li>영어와 달리 각 한글 문자는 [자음 + 모음], [자음 + 모음 + 자음] 과 같이 2개 또는 3개의 자소 조합으로 표현된다. </li>
<li>총 문자 수는 11,172자에 달하며 이는 표현 능력에서 소프트맥스 계층을 쉽게 고갈시킬 수 있다. </li>
<li>따라서 현재 한글 OCR 시스템은 문자의 일부만 활용하고 가장 많이 사용되는 1000자 정도를 유지하고 있다.</li>

<br>

<b>2) 이전 연구의 한계 :</b> 
<li>이전 접근 방식은 균일하게 분포된 문자를 제공하기 위해 가상 이미지를 생성하려고 시도했지만 대상 도메인을 얻는 데 중요하지 않을 수 있는 문자를 학습하기 위한 추가 학습 시간이 발생한다.</li>

<br>

<b>3) 해결책 제시</b>
<li>이 문제를 해결하기 위해 문자를 자소로 분해할 것을 제안한다.</li>
<li>한글은 자음과 모음이 위치마다 정해진 규칙(첫 자음+모음 또는 첫자음+모음+마지막 자음)으로 존재하므로 인식 대상을 문자에서 자소로 변경하면 11,172개 클래스를 52개 클래스로 분류하는 문제를 대체할 수 있다.</li>
<li>이 분해에는 두 가지 주요 이점이 있다. 첫 번째, 모델이 문자의 다수 클래스와 소수 클래스의 자소를 동일한 자소 클래스로 분류하는 방법을 배우게 함으로써 클래스 불균형 문제가 크게 완화된다.</li>
<li>두 번째, 기존에 학습한 자음과 모음을 조합하여 학습하지 않은 문자도 인식할 수 있어 한글 전체의 문자 인식이 가능하다.</li>
<li>한국어 텍스트 인식 작업에 대한 벤치마크를 구축하고 제안한 방법의 효과를 실험적으로 검증하였다.</li>


<h2>2. Related Work</h2>

<b>1) 기존 사용 사례</b>
<li>번호판 인식</li> 
<li>필기체 인식</li>
<li>신용 카드 번호 인식</li>

<br>

<b>2) 기존 인식 작업</b> 
<li>시퀀스 예측으로 모델링했다.</li> 
<li>시각적 특징은 ResNet과 같은 CNN backbone에서 추출되고 LSTM 및 GRU와 같은 RNN 계층에 공급되어 연결주의적 시간분류(CTC)로 훈련된다.</li>

<br>

<b>3) 최근 접근 방식</b> 
<li>자연어 처리에서 개발된 Transformer의 Attention 매커니즘에서 영감을 받아 Image patch 간의 상호 작용을 모델링하는 ViT(Vision Transformer)와 같은 보다 강력한 backbone을 사용한다.</li>

<br>

<b>4) 기존 연구 한계</b>
<li>자주 사용하는 문자만 선택하여 학습 : 선택한 집합 외부의 문자를 절대 인식할 수 없다.</li>
<li>11,172자 모두 학습 : 실제 상황에서 거의 나타나지 않는 문자를 분류하기 위해 더 넓은 범위의 문자를 포함하는 많은 데이터가 필요하다.</li>
<li>학습된 모델을 다른 도메인 간에 전송할 수 있는지 여부는 불분명하다.</li>

<h2>3. Method</h2>
<li>한글 장면 텍스트 인식의 경우 입력은 이미지이고 출력은 한글 텍스트이다.</li>
<li>인코더-디코더 구조를 사용했다.</li>
<li>인코더 : CNN 레이어 φ 와 Transformer Unit ψ 은 문자를 정의하는 자소 간의 Context를 학습하는데 사용된다.</li>
<li>디코더 : 주어진 Feature Map의 각 자소에 해당하는 Feature에 속하는 방법을 학습한다.</li>
<li>자소가 존재하지 않는 예외적인 유형의 문자가 있는데 이 경우를 처리하는 방법은 [첫자음,모음] 구조와 [첫자음,모음,마지막자음]구조의 두 가지 다른 유형의 문자를 단일 구조로 통합하기 위해 "무성음"이라는 가상 클래스를 추가했다.</li>

<h2>4. Experiments</h2>
<h3>4.1 Datasets</h3>

<h3>4.2 Implementation Details</h3>
<h3>4.3 Experimental Settings</h3>
<h3>4.4 Quantitative Results</h3>
<h3>4.5 Further Analysis</h3>


<h2>5. Conclusion</h3>


<br>

<a href='https://arxiv.org/abs/2208.06079'>논문 원본 보기</a>